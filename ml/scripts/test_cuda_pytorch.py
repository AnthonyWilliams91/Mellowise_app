import torch
import sys

print("üß™ CUDA + PyTorch Test")
print("=" * 23)
print(f"Python version: {sys.version}")
print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    print(f"CUDA version: {torch.version.cuda}")
    print(f"cuDNN version: {torch.backends.cudnn.version()}")
    print(f"GPU count: {torch.cuda.device_count()}")
    
    for i in range(torch.cuda.device_count()):
        gpu = torch.cuda.get_device_properties(i)
        print(f"GPU {i}: {gpu.name}")
        print(f"  Memory: {gpu.total_memory / 1e9:.1f} GB")
        print(f"  Compute capability: {gpu.major}.{gpu.minor}")
    
    # Quick GPU computation test
    print("\nüöÄ Testing GPU computation...")
    try:
        device = torch.device("cuda:0")
        x = torch.randn(1000, 1000, device=device)
        y = torch.randn(1000, 1000, device=device)
        z = torch.matmul(x, y)
        print(f"‚úÖ GPU computation successful! Result shape: {z.shape}")
        print(f"   Device: {z.device}")
        
        # Performance comparison
        import time
        
        # CPU test
        x_cpu = torch.randn(1000, 1000)
        y_cpu = torch.randn(1000, 1000)
        start = time.time()
        z_cpu = torch.matmul(x_cpu, y_cpu)
        cpu_time = time.time() - start
        
        # GPU test
        x_gpu = torch.randn(1000, 1000, device=device)
        y_gpu = torch.randn(1000, 1000, device=device)
        torch.cuda.synchronize()
        start = time.time()
        z_gpu = torch.matmul(x_gpu, y_gpu)
        torch.cuda.synchronize()
        gpu_time = time.time() - start
        
        print(f"\n‚ö° Performance comparison:")
        print(f"   CPU time: {cpu_time:.4f}s")
        print(f"   GPU time: {gpu_time:.4f}s")
        print(f"   Speedup: {cpu_time/gpu_time:.1f}x")
        
    except Exception as e:
        print(f"‚ùå GPU computation failed: {e}")
else:
    print("‚ùå CUDA not available")
    print("\nTroubleshooting:")
    print("1. Ensure NVIDIA drivers are installed on Windows")
    print("2. Ensure CUDA toolkit is installed in WSL2")
    print("3. Check environment variables (PATH, LD_LIBRARY_PATH)")

# Test RecBole with potential GPU support
print("\nüìö Testing RecBole...")
try:
    import recbole
    print(f"RecBole version: {recbole.__version__}")
    print("‚úÖ RecBole import successful")
except ImportError as e:
    print(f"‚ùå RecBole import failed: {e}")

print("\nüéØ Ready for ML training!")
